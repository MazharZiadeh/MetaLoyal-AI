# MetaLoyal: Learning Human-Like Loyalty in Reinforcement Learning Agents

MetaLoyal is an experimental framework to train AI agents to exhibit *loyalty*â€”a persistent commitment to another agent or value systemâ€”even when faced with short-term gain from betrayal.

## ðŸ§  Project Overview
This project implements a custom environment (`TemptationBridgeEnv`) where agents must choose between loyalty and betrayal, receiving shaped rewards based on their loyalty score.

We train RL agents using `Stable-Baselines3` and analyze their emergent behavior under different loyalty shaping parameters.

